{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/home/baldeeb/Code/pytorch-NOCS')\n",
    "\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNN_ResNet50_FPN_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.load_save import load_nocs\n",
    "from torch.optim import Adam\n",
    "import torch\n",
    "\n",
    "from habitat_datagen_util.utils.dataset import HabitatDataset\n",
    "from habitat_datagen_util.utils.collate_tools import collate_fn\n",
    "\n",
    "from utils.spot_dataset import SpotDataset, collate_fn \n",
    "\n",
    "DATA_DIR = '/home/baldeeb/Code/bd_spot_wrapper/data/output/front_left'\n",
    "CHKPT_DIR = \"/home/baldeeb/Code/pytorch-NOCS/checkpoints/nocs_classification/2023-05-25_13-46-18/one_class_frozen_backbone_4.pth\"\n",
    "device= 'cuda:1'\n",
    "\n",
    "model = load_nocs(CHKPT_DIR,\n",
    "                maskrcnn_weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT,\n",
    "                nocs_num_bins=32,\n",
    "                nocs_loss_mode = 'classification',\n",
    "                multiheaded_nocs = True,)\n",
    "model.to(device).train()\n",
    "\n",
    "habitatdata = SpotDataset(DATA_DIR)\n",
    "dataloader = DataLoader(habitatdata, \n",
    "                        batch_size=2, \n",
    "                        collate_fn=collate_fn)\n",
    "optimizer = Adam(model.parameters(keys=['nocs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "poses = []\n",
    "for im, tgt in dataloader:\n",
    "    poses.append(tgt[0]['camera_pose'])\n",
    "poses = torch.stack(poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "for i in range(len(poses)-2):\n",
    "    plt.figure()\n",
    "    pose = poses[i:i+2]\n",
    "    a = [1/v for v in range(1, len(pose)+1)]\n",
    "    plt.plot(pose[0:1, 0,3], pose[0:1, 2,3], alpha=1)\n",
    "    plt.plot(pose[1:2, 0,3], pose[1:2, 2,3], alpha=0.5)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.roi_heads.training_mode('multiview')\n",
    "for itr, (images, targets) in enumerate(dataloader):\n",
    "    images = images.to(device)\n",
    "    # targets = targets2device(targets, device)\n",
    "    losses = model(images, targets)\n",
    "    loss = sum(losses.values())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(losses['multiview_consistency_loss'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
